{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aware-disclosure",
   "metadata": {},
   "source": [
    "# Create Out-of-domain File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjusted-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-genesis",
   "metadata": {},
   "source": [
    "## Importing subreddit files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acting-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(filepath: str) -> List[str]:\n",
    "    f = open(filepath, \"r\")\n",
    "    text = f.readlines()\n",
    "    f.close()\n",
    "    return text\n",
    "    \n",
    "def write_txt(filepath: str, text: List[str]) -> None:\n",
    "    f = open(filepath, \"w\")\n",
    "    for line in text: f.write(line + \"\\n\")\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "harmful-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subreddit_file(domain: str, filename: str, regex: str) -> None:\n",
    "    # reading file into list\n",
    "    raw_filepath = \"./text-classifier/{}-domain/raw/{}.txt\".format(domain, filename)\n",
    "    clean_filepath = \"./text-classifier/{}-domain/clean/{}.txt\".format(domain, filename)\n",
    "    \n",
    "    text = read_txt(raw_filepath)\n",
    "    \n",
    "    # deleting duplicates\n",
    "    text = list(set(text))\n",
    "    \n",
    "    # regex cleaning\n",
    "    text = [re.sub(regex, \"\", line) for line in text]\n",
    "    \n",
    "    # removing whitespace\n",
    "    text = [line.strip() for line in text]\n",
    "    \n",
    "    # writing list to file\n",
    "    write_txt(clean_filepath, text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "buried-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_case_regex(word: str) -> str:\n",
    "    regex = r\"\"\n",
    "    \n",
    "    for letter in word:\n",
    "        lower = letter.lower()\n",
    "        upper = letter.upper()\n",
    "        regex += \"[{}{}]\".format(upper, lower)\n",
    "        \n",
    "    return regex\n",
    "\n",
    "RE_OPEN_BRACKET = r\"[\\[\\(]?\"\n",
    "RE_CLOSE_BRACKET = r\"[\\]\\)]?\"\n",
    "RE_UNTIL_ALPHANUM = r\"([\\W]+)\"\n",
    "RE_SECOND_WORD = r\"([\\w]+)([\\W]+)\"\n",
    "RE_END_QUESTION_MARK = r\"|\\?$\"\n",
    "\n",
    "RE_REMOVE_QUESTIONS = r\"^({}|{}|{}|{}|{}|{}|{}|{})\".format(\n",
    "    any_case_regex(\"who\"),\n",
    "    any_case_regex(\"what\"),\n",
    "    any_case_regex(\"where\"),\n",
    "    any_case_regex(\"which\"),\n",
    "    any_case_regex(\"how\"),\n",
    "    any_case_regex(\"when\"),\n",
    "    any_case_regex(\"why\"),\n",
    "    any_case_regex(\"whose\"),\n",
    ")\n",
    "\n",
    "RE_SQUARE_BRACKETS = r\"\\[.+\\]\"\n",
    "RE_ROUND_BRACKETS = r\"\\(.+\\)\"\n",
    "\n",
    "RE_SERIOUS = any_case_regex(\"serious\")\n",
    "RE_NSFW = any_case_regex(\"nsfw\")\n",
    "RE_QUESTIONS = RE_OPEN_BRACKET + RE_REMOVE_QUESTIONS + RE_CLOSE_BRACKET + RE_UNTIL_ALPHANUM + RE_SECOND_WORD + RE_END_QUESTION_MARK\n",
    "RE_ELI5 = RE_OPEN_BRACKET + any_case_regex(\"eli5\") + RE_CLOSE_BRACKET + RE_UNTIL_ALPHANUM\n",
    "RE_TIFU = RE_OPEN_BRACKET + any_case_regex(\"tifu\") + RE_CLOSE_BRACKET + RE_UNTIL_ALPHANUM + \"(\" + any_case_regex(\"by\") + \")\" \"?\"\n",
    "RE_LPT = RE_OPEN_BRACKET + any_case_regex(\"lpt\") + RE_CLOSE_BRACKET + RE_UNTIL_ALPHANUM\n",
    "RE_TIL = RE_OPEN_BRACKET + any_case_regex(\"til\") + RE_CLOSE_BRACKET + RE_UNTIL_ALPHANUM\n",
    "RE_YSK = RE_OPEN_BRACKET + any_case_regex(\"ysk\") + RE_CLOSE_BRACKET + RE_UNTIL_ALPHANUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inner-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_domain = [\n",
    "    (\"AskReddit\", RE_SQUARE_BRACKETS + \"|\" + RE_QUESTIONS),\n",
    "    (\"CasualConversation\", RE_SQUARE_BRACKETS),\n",
    "    (\"CrazyIdeas\", RE_SQUARE_BRACKETS),\n",
    "    (\"explainlikeimfive\", RE_SQUARE_BRACKETS + \"|\" + RE_ELI5),\n",
    "    (\"Jokes\", RE_SQUARE_BRACKETS),\n",
    "    (\"lifehacks\", RE_SQUARE_BRACKETS),\n",
    "    (\"LifeProTips\", RE_SQUARE_BRACKETS + \"|\" + RE_LPT),\n",
    "    (\"mildlyinteresting\", RE_SQUARE_BRACKETS),\n",
    "    (\"news\", RE_SQUARE_BRACKETS),\n",
    "    (\"nosleep\", RE_SQUARE_BRACKETS),\n",
    "    (\"pettyrevenge\", RE_SQUARE_BRACKETS),\n",
    "    (\"ShowerThoughts\", RE_SQUARE_BRACKETS),\n",
    "    (\"tifu\", RE_SQUARE_BRACKETS + \"|\" + RE_TIFU),\n",
    "    (\"todayilearned\", RE_SQUARE_BRACKETS + \"|\" + RE_TIL),\n",
    "    (\"worldnews\", RE_SQUARE_BRACKETS),\n",
    "    (\"YouShouldKnow\", RE_SQUARE_BRACKETS + \"|\" + RE_YSK),\n",
    "]\n",
    "\n",
    "\n",
    "for filename, regex in out_domain:\n",
    "    clean_subreddit_file(\"out\", filename, regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "needed-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(domain, subreddits: List[str]) -> None:\n",
    "    combined = []\n",
    "    \n",
    "    for subreddit in subreddits:\n",
    "        path = \"./text-classifier/{}-domain/clean/{}.txt\".format(domain, subreddit)\n",
    "        text = read_txt(path)\n",
    "        combined.extend(text)\n",
    "        \n",
    "    f = open(\"./text-classifier/{0}-domain/{0}-domain.txt\".format(domain), \"w+\")\n",
    "    for line in combined: f.write(line)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "documented-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_files(\"out\", [x[0] for x in out_domain])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-apparel",
   "metadata": {},
   "source": [
    "# Create In-domain File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sweet-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_domain = [\n",
    "    (\"Food\", RE_SQUARE_BRACKETS),\n",
    "    (\"FoodPorn\", RE_SQUARE_BRACKETS),\n",
    "]\n",
    "\n",
    "\n",
    "for filename, regex in in_domain:\n",
    "    clean_subreddit_file(\"in\", filename, regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "broke-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_files(\"in\", [x[0] for x in in_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-paste",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
